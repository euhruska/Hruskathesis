\afterpage{\null\newpage}
\chapter{Adaptive sampling software framework\label{ch:chapter4}}
\section{\label{sec:intro4}Introduction}

One of the motivations of utilizing \emph{Adaptive sampling} is reaching longer timescales in the practical application of sampling biomolecules and obtaining accurate kinetic behavior. This requires to execute a hierarchical ensemble of tasks in an efficient fashion on every level. Without efficient execution of all the subtasks of adaptive sampling, the goal of reaching longer timescales wouldn't be realistic. In practice, the higher complexity of executing adaptive sampling compare to plain Molecular dynamics reduces the practical utilization of the advantages of adaptive sampling. Here we design and develop a software framework that reduces the entry barrier to implement adaptive sampling by domain experts. Some of the objectives establishing the software frameworks are scalability, maintainability, flexibility, and extensibility.
The scalability objective is fundamental to efficiently utilize the limited computational resources on High-Performance Computers (HPC). Easy maintainability should reduce the entry barrier to execute adaptive sampling. The flexibility and extensibility of this software framework should enable adjusting for new sampling methods, individual molecular dynamics software choices, and different HPCs or supercomputers. In this Chapter we will discuss the development of the \emph{ExTASY} software package and how ExTASY implements the beforementioned objectives.

The material in this Chapter was first published in the following papers: 
\\*
\cite{Extasy2016} Balasubramanian, V.; Bethune, I.; Shkurti, A.; Breitmoser, E.; \textbf{Hruska, E.}; Clementi, C.; Laughton, C.; Jha, S.; Extasy: Scalable and flexible coupling of md simulations
and advanced sampling techniques. Proceedings of the 2016 IEEE 12th
International Conference on e-Science 361{370 (2016).
\\*
\cite{Extasy2019} \textbf{Hruska, E.}; Balasubramanian, V.; Ossyra, J. R.; Jha, S.; Clementi, C.; Extensible
and scalable adaptive sampling on supercomputers. arXiv (2019). URL: https://arxiv.org/abs/1907.06954.


\section{\label{sec:alternative4}Alternative software}

Previously multiple groups have developed software packages that strive to achieve the same objectives for the execution of adaptive sampling. Still, all these frameworks have some limitations which we attempt to overcome with \emph{ExTASY}.
The package HTMD\cite{doerr2016htmd} has shown the effective adaptive sampling performance for small proteins, including effective retrieval of kinetic information. The performance for larger proteins and the scalability is not yet shown. The entry barrier for the utilization of HTMD is increased by not being open-sourced. Further, HTMD supports only one single molecular dynamics engine and a limited number of adaptive sampling strategies.

The recent package DeepDriveMD \cite{leeDeepDriveMDDeepLearningDriven2019} allows to utilize deep learning in adaptive sampling, and it is able to execute on heterogeneous software and hardware environments scalably. Still, DeepDriveMD has not yet released or open-sourced the code yet. 

The SSAGES (Software Suite for Advanced General Ensemble Simulations) \cite{SSAGES} is open-source and flexible, not bound to specific molecular dynamics engines. Still, the effectivity and scalability for large proteins remain to be shown. Multiple software frameworks \cite{jung2019acp, ribeiro2018tjocp, bonati2019pnasu} show the effective sampling of toy systems and small peptides with the ability to utilize strategies with neural networks but haven't shown the extensibility to larger systems or the scalability to perform efficiently for larger applications. 



\section{\label{sec:asynch}Asynchronous execution}

One crucial feature of ExTASY is the ability for asynchronous execution of the individual subtasks. As far as we know, no other adaptive sampling platform enables asynchronous execution. This significantly improves the efficiency of adaptive sampling in practice. In the standard, synchronous execution, all previous steps have to be concluded to begin the next step. 
The Steps 2-4 mentioned in Chapter 3 Figure~\ref{fig:schema2} require very low parallelization compared to Step 1. Steps 2-4 shows the analysis, and Step 1 shows the execution of all molecular dynamics trajectories. In a typical use case, Step 1 utilizes a large number of GPUs due to the large number of replicas simultaneously simulated. Once Step 1 finishes, then Steps 2-4 are run, which typically utilizes a fraction of nodes or GPUs compared to Step 1. When running on a constant number of nodes or GPUs, which is the most common case on HPCs, this low utilization of nodes for Step 2-4 is reduced. This performance penalty is more substantial when the adaptive sampling steps take a longer time to finish, for example, for a more complex strategy or larger biomolecules. The asynchronous execution shown in Figure~\ref{fig:asynch} allows to increase the utilization of computational resources and consequently to reach longer timescales by continuously utilizing all nodes or GPUs and removing the downtimes for MD workers. The MD tasks require new restarting configurations to start the simulations. These new restarting configurations are continuously updated by repeatedly running the adaptive sampling analysis steps. This generated new restarting configurations, which take into account the recently partially unfinished molecular dynamics tractories. Due to the time delay of finishing adaptive sampling analysis, a small fraction at the end of MD trajectories won't be analyzed, but in the next restarting point, these small parts will be analyzed.
The first version of ExTASY\cite{Extasy2016} had only synchronous execution enabled, but the current \cite{Extasy2019} includes asynchronous execution. In chapters 5 and 6, all the adaptive sampling is executed asynchronously. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{figures2/asynch.pdf}
  \caption{Asynchronous execution of the ensemble of adaptive sampling subtasks, including molecular dynamics and analysis tasks. The restart configurations for the next molecular dynamics simulation are determined by the last finished analysis task. Here steps 2 and 4 are shown combined as analysis steps.}
  \label{fig:asynch}
\end{figure}



\section{\label{sec:Tools}Tools and Software}

ExTASY was built by utilizing the RADICAL-Cybertools \cite{Balasubramanian2019rct}. The RADICAL-Cybertools are software systems designed to execute ensembles of tasks on HPC platforms in a scalable and modular approach.

ExTASY uses the RADICAL-Cybertools component EnTK (Ensemble Toolkit)
\cite{entk-icpp-2016, balasubramanian2018harnessing} to communicate with RADICAL-Cybertools. The EnTK layer enables to abstract the execution of individual tasks from the explicit resource
management. In the background, hidden from ExTASY, RADICAL-Cybertools performs the explicit resource acquisition and resource management in a scalable fashion as well as error tracking and analytics. The whole RADICAL-Cybertools was built in a blocks approach \cite{turilli2018building}, allowing modularity and flexibility for ExTASY.


\begin{figure}[h!]
    \begin{lstlisting}
    from @radical.entk@ import @Task, Stage, Pipeline@
    p = Pipeline()

    sim_stage = Stage()   
    sim_task = Task()
    sim_task.executable = @<executable>@ #example openmm
    sim_task.arguments = <args> #example openmm args
    <add other task properties>
    sim_stage.add_tasks(sim_task)
    
    ana_stage = Stage()
    ana_task = Task()
    ana_task.executable = @<executable>@ #example pyemma
    ana_task.arguments = <args> #example pyemma args
    <add other task properties>
    
    ana_stage.add_tasks(ana_task)
    ana_stage.post_exec = {
        'condition': eval_sims(),
        'on_true':   add_sims(),
        'on_false':  terminate()
        }
    
    p.add_stages([sim_stage, ana_stage])
    \end{lstlisting}
    \caption{Pseudocode showing the modular software design and the EnTK API backend}\label{extasy_snippet}
\end{figure}


Figure~\ref{extasy_snippet} shows pseudo-code illustrating the ExTASY implementation of adaptive sampling with EnTK API. The individual separation of simulation and analysis tasks is recognizable. Figure~\ref{fig:extasy_arch} shows the modular integration between ExTASY and EnTK. ExTASY describes adaptive sampling as a set of executable tasks. ExTASY determines the parameters for the Resource description (event 1) and the MD and analysis tasks (event 2). ExTASY then passes these parameters to the EnTK's interface, which defines the resource and application (events 3 and 4). Once defined, EnTK starts the execution of the executable ExTASY tasks on the target resource (events5, 6, and 7). 

\begin{figure}[H]
 \centering
  \includegraphics[width=0.8\textwidth]{figures2/extasy_arch_coarse.pdf}
  \caption{EnTK backend: This schema shows the modularity which enables ExTASY's scalability which ensuring flexibity.  
  }\label{fig:extasy_arch}
\end{figure}


\section{Pilot abstraction} 
One reason for ExTASY to utilize RADICAL-Cybertools is the improved ability to execute tasks on computational resources. Traditionally multiple HPC tasks can be executed either as individual jobs or with message-passing interface (MPI) as part of a single job. The first approach is effective for independent tasks, but for interdependent tasks as in adaptive sampling, this approach is suboptimal. The second method is suboptimal for the heterogeneous and adaptive tasks in adaptive sampling. The pilot abstraction in RADICAL-Cybertools~\cite{turilli2018comprehensive} overcomes these limitations.  The pilot abstraction separates the initial computational resource acquisition from individual task-to-resource assignments. First, the computational resources are requested with placeholder jobs without any tasks. In the second step, while the job is running, individual tasks are assigned to the placeholder jobs. RADICAL-Cybertools is engineered to support scalable pilot abstraction for launching heterogeneous tasks across different platforms. This pilot abstraction of the RADICAL-Cybertools allows ExTASY to execute all the individual subtasks of adaptive sampling effectively.  

\section{\label{sec:scaling}Scaling}


One of the main metrics to deploy tools to Supercomputers is the scalability. Only algorithms with sufficient parallelization can utilize these computational resources effectively. The scalability of adaptive sampling depends both on the scalability of the software platform and the scalability of the individual MD engines and analysis tools. To abstract only the scalability of the software platform, we define the efficiency as the ratio between the nodehours used by all the individual tasks and the nodehours used by the software platform. 
This efficiency was measured for increasing parallelizations up to 2000 GPUs on Summit, shown in Figure~\ref{fig:scaling}. With the asynchronous execution, one GPU was tasked to run analysis tasks; all other GPUs were running MD tasks. 6 GPUs per node and 2 hour-long computational jobs were utilized. The efficiency of ExTASY above 2000 GPUs is reduced due to the time delay caused by communication between individual RADICAL components. RADICAL-Cybertools adapts to the specific software environments of the HPCs\cite{turilli2019ac}, improving the scalability and illustrating the advantage of platform-agnostic execution and portability across
heterogeneous HPC resources. The asynchronous version of ExTASY allows scaling to a higher number of nodes than alternative adaptive sampling software platforms.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{figures2/plot_scalingefficiencylog.pdf}
  \caption{Scaling of ExTASY on Summit. The Efficiency is defined as the ratio between the nodehours used by all the individual tasks and the nodehours used by the software platform. }
  \label{fig:scaling}
\end{figure}



\section{\label{sec:conclusion}Conclusion}
This thesis shows the development of the ExTASY framework, which achieves several objectives to enable effective execution of adaptive sampling workloads. Scalability of over 1000 GPUs and 1000 replicas was demonstrated on the supercomputer Summit. This scalability reduces the technical barrier to adaptive sampling for larger proteins. Notably, this scalability doesn't reduce the flexibility of the platform.

The open-source nature of the ExTASY framework is an important feature. The code is available at \href{https://github.com/ClementiGroup/ExTASY}{https://github.com/ClementiGroup/ExTASY}. By releasing the platform open-source, the implementation of new adaptive sampling strategies is simplified. This flexibility allowed ExTASY to be the first open-source, adaptive sampling platform that supports deep learning or asynchronous execution. The asynchronous execution significantly improves the utilization of computational resources for larger proteins or more complex adaptive sampling strategies.

The modularity of this software platform enables multiple objectives. One objective is the agnosticism from the HPC platform, preventing code working only for specific software and hardware environments. The modularity also improves the maintainability, reliability, and reproducibility of adaptive sampling. 